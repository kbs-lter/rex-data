---
title: "Untitled"
author: "Moriah Young"
date: "2024-04-29"
output: pdf_document
---

Import demultiplexed sequences into .qza artifact for downstream pipeline using Qiime2
```{bash}
cd /mnt/home/youngmor/20240415_16SV4_PE250
qiime tools import 
--type 'SampleData[PairedEndSequencesWithQuality]' \
--input-path 20240415_16SV4_PE250_manifest.txt/ \
--input-format PairedEndFastqManifestPhred33V2 \
--output-path 20240415_16SV4_PE250.qza \

# enter the code below in one string like this to run on the hpcc
qiime tools import --type 'SampleData[PairedEndSequencesWithQuality]' --input-path 20240415_16SV4_PE250_manifest.txt --input-format PairedEndFastqManifestPhred33V2 --output-path 20240415_16SV4_PE250.qza

````

Denoise sequences using dada2
```{bash}
qiime demux summarize \
--i-data 20240415_16SV4_PE250.qza \
--o-visualization 20240415_16SV4_PE250_PE250_SUMMARY_VIZ.qzv
qiime tools view 20240415_16SV4_PE250_PE250_SUMMARY_VIZ.qzv # https://view.qiime2.org/

qiime demux summarize --i-data 20240415_16SV4_PE250.qza --o-visualization 20240415_16SV4_PE250_PE250_SUMMARY_VIZ.qzv
```

Create a .qzv file so you can check out the table from the denoising stats that was created from the job above
You can then drag and drop the .qzv file into this website: https://view.qiime2.org/ 
You'll need to download it from the interactive interface onto your mac
```{bash}
# Run 1
cd /mnt/home/youngmor/20240415_16SV4_PE250
qiime metadata tabulate \
  --m-input-file 20240415_16SV4_PE250-denoising-stats.qza \
  --o-visualization 20240415_16SV4_PE250-denoising-stats.qzv
  
qiime metadata tabulate --m-input-file 20240415_16SV4_PE250-denoising-stats.qza --o-visualization 20240415_16SV4_PE250-denoising-stats.qzv
```

# Training a classifier
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5069754/ # primers
```{bash}
cd /mnt/home/youngmor/20240415_16SV4_PE250
# test the classifier
qiime feature-classifier classify-sklearn \
  --i-classifier classifier.qza \
  --i-reads 20240415_16SV4_PE250-rep-seqs.qza \
  --o-classification 16S-taxonomy-2023.qza

qiime feature-classifier classify-sklearn --i-classifier classifier.qza --i-reads 20240415_16SV4_PE250-rep-seqs.qza --o-classification 16S-taxonomy-2023.qza

# visualize
qiime metadata tabulate \
  --m-input-file 16S-taxonomy-2023.qza \
  --o-visualization 16S-taxonomy-2023.qzv

# testing the classifier and creating the .qzv file took 7 hours on the hpcc (using the same SLURM code/settings as the denoising script above)
  
qiime metadata tabulate --m-input-file 16S-taxonomy-2023.qza --o-visualization 16S-taxonomy-2023.qzv
```

# create mapping/metadata file
```{r}
# Set working directory from .Renviron
dir <- Sys.getenv("DATA_DIR")
list.files(dir)

library(tidyverse)

# read in data
microbe_metadata <- read.csv(file.path(dir, "microbes/16S & ITS/T7_warmx/L0/2023/files to create REX 16S 2023 metadata/MY_REX_soil_microbes_2023_metadata.csv"))
warmx_metadata <- read.csv(file.path(dir, "microbes/16S & ITS/T7_warmx/L0/2023/files to create REX 16S 2023 metadata/REX_warmx_metadata.csv"))

# rename columns to match each other
names(microbe_metadata)[names(microbe_metadata) == "Plot_ID"] <- "Unique_ID"
names(microbe_metadata)[names(microbe_metadata) == "FP_location"] <- "Footprint_Location"
names(microbe_metadata)[names(microbe_metadata) == "Subplot_location"] <- "Subplot_Location"

# merge files above
bacterial_2023_metadata <- full_join(microbe_metadata, warmx_metadata, by = c("Unique_ID", "Treatment", "Replicate",
                                      "Footprint", "Footprint_Location", "Subplot", "Subplot_Location"))

# delete columns
# Unique_Field_Location_Code, Experimental_Unit_ID
bacterial_2023_metadata <- subset(bacterial_2023_metadata, select = -c(Unique_Field_Location_Code, Experimental_Unit_ID, Footprint_ID))

# reorder columns
bacterial_2023_metadata <- bacterial_2023_metadata[, c("Sample_ID", "Treatment", "Replicate", "Rep", "Footprint",
                                                       "Footprint_Location", "Rep_Footprint", "Footprint_Treatment_full",
                                                       "Subplot", "Subplot_Location", "Drought", "Warming",
                                                       "Insecticide", "Subplot_Descriptions",
                                                       "Unique_ID", "Date")]

seq_metadata <- read.csv(file.path(dir, "microbes/16S & ITS/T7_warmx/L0/2023/files to create REX 16S 2023 metadata/sequence_2023_metadata.csv"))

# rename columns to match each other
names(seq_metadata)[names(seq_metadata) == "Sample_ID"] <- "RTSF_SampleID"
names(seq_metadata)[names(seq_metadata) == "Sample.Name"] <- "Sample_ID"

bacterial_2023_metadata <- full_join(seq_metadata, bacterial_2023_metadata, by = "Sample_ID")

# reorder columns
bacterial_2023_metadata <- bacterial_2023_metadata[, c("Sample_ID", "RTSF_SampleID", "Barcode",
                                                       "LinkerPrimerSequence", "Reverse_Primer", 
                                                       "MiSeqRun", "Treatment", "Replicate", 
                                                       "Rep", "Footprint", "Footprint_Location", 
                                                       "Rep_Footprint", "Footprint_Treatment_full",
                                                       "Subplot", "Subplot_Location", "Drought", "Warming",
                                                       "Insecticide", "Subplot_Descriptions",
                                                       "Unique_ID", "Date")]

colnames(bacterial_2023_metadata)[1] <- "sampleid"

# get rid of controls
#bacterial_2021_metadata <- bacterial_2021_metadata[!grepl("CONTROL", bacterial_2021_metadata$sampleid),]
#bacterial_2021_metadata <- bacterial_2021_metadata %>% na.omit() # get rid of line 227 which is sample 36 (sample not submitted to RTSF)

# write a new csv with the cleaned and merge data 
write.csv(bacterial_2023_metadata, file = "/Users/moriahyoung/Downloads/bacterial_2023_metadata.csv", row.names = F)
#write.table(bacterial_2021_metadata, file = "/Users/moriahyoung/Downloads/bacterial_2021_metadata.tsv", quote = F, sep = #",", row.names = F)
```

Cleaning and steps to make a phyloseq object
```{r}
library(qiime2R)
# Read QZA files into dataframe, re-format taxonomic tables, and re-upload them as .csv files
# Code below you only need to do once
SVs16S <- read_qza("/Users/moriahyoung/Downloads/16S-2023-dada2table.qza")
SVs16Stable <- SVs16S$data
write.csv(SVs16Stable, file = "/Users/moriahyoung/Downloads/16S-2023-dada2table.csv")

taxonomy16S <- read_qza("/Users/moriahyoung/Downloads/16S-2023-taxonomy.qza")
tax16S <- taxonomy16S$data %>% as_tibble() %>%
  mutate(Taxon=gsub("[a-z]__", "", Taxon)) %>% 
  separate(Taxon, sep=";", c("Kingdom","Phylum","Class","Order","Family","Genus","Species"))%>%
  mutate(Phylum=replace_na(Phylum,"empty"))
write.csv(tax16S, file = "/Users/moriahyoung/Downloads/16S-2023-taxonomy.csv", row.names =F)
```

Filter data
```{r}
library(phyloseq)
library(microbiome)
# create phyloseq object
data_16S_unfiltered <- read_csv2phyloseq(otu.file = "/Users/moriahyoung/Downloads/16S-2023-dada2table.csv",
                                         taxonomy.file = "/Users/moriahyoung/Downloads/16S-2023-taxonomy.csv",
                                         metadata.file = "/Users/moriahyoung/Downloads/bacterial_2023_metadata.csv")
summarize_phyloseq(data_16S_unfiltered)

# filter out non bacteria
data_16S_uf1 <- subset_taxa(data_16S_unfiltered, Kingdom == "Bacteria" | Kingdom == "Archaea")
data_16S_uf2 <- subset_taxa(data_16S_uf1, Kingdom != "Eukaryota")
data_16S_uf3 <- subset_taxa(data_16S_uf2, Order != "Chloroplast")
data_16S_uf4 <- subset_taxa(data_16S_uf3, Family != "Mitochondria")

summarize_phyloseq(data_16S_uf4)

# Remove samples with extremely low read depth 
# data_16S_uf5 <- prune_samples(sample_sums(data_16S_uf4)>=1000, data_16S_uf4)

# Export filtered data
write.csv(data_16S_uf5@otu_table, "/Users/moriahyoung/Desktop/phyloseq_object/16S-merged-table-filtered.csv")
write.csv(data_16S_uf5@tax_table, "/Users/moriahyoung/Desktop/phyloseq_object/16S-taxonomy-filtered.csv")
# upload these to REX google shared drive
# update path
write.csv(data_16S_uf5@tax_table, file.path(dir,"soil/L1/T7_warmx_soil_moisture_2022_L1.csv"), row.names=F)
```


